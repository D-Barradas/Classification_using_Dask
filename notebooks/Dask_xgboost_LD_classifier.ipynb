{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "martial-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "from dask import compute, persist\n",
    "from dask.distributed import Client, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.dataframe as dd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from dask_ml.preprocessing import StandardScaler,LabelEncoder\n",
    "from dask_ml.model_selection import HyperbandSearchCV ,RandomizedSearchCV,KFold\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dask.array as da\n",
    "from sklearn.metrics import classification_report,matthews_corrcoef\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.stats import uniform, loguniform \n",
    "from dask_ml.xgboost import XGBClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "# import xgboost.XGBRFClassifier as xRFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metropolitan-documentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask version 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "print (f'Dask version {dask.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composed-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=False, threads_per_worker=4,\n",
    "                n_workers=1, memory_limit='16GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varying-constraint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://10.228.0.65/20962/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.228.0.65:8787/status' target='_blank'>http://10.228.0.65:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://10.228.0.65/20962/1' processes=1 threads=4, memory=16.00 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "million-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_BM5 = [\n",
    "'1EXB','1JTD','1M27','1RKE','2A1A','2GAF','2GTP','2VXT','2W9E',\n",
    "'2X9A','2YVJ','3A4S','3AAA','BAAD','3AAD','3BIW','3BX7',\n",
    "'3DAW','3EO1','3EOA','3F1P','3FN1','3G6D','3H11',\n",
    "'3H2V','3HI6','3HMX','3K75','3L5W','3L89','3LVK','3MXW',\n",
    "'BP57','CP57','3P57','3PC8','3R9A','3RVW','3S9D','3SZK',\n",
    "'3V6Z','3VLB','4DN4','4FQI','4FZA','4G6J','4G6M','4GAM',\n",
    "'4GXU','4H03','4HX3','4IZ7','4JCV','4LW4','4M76'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_sets():\n",
    "    all_balanced_data = dd.read_csv(\"../data/Clean_dataframe_balanced_all_data_ccharppi_4_march_2020_complete.csv\")\n",
    "    all_balanced_data = all_balanced_data.drop(\"class_q\",axis=1)\n",
    "    all_balanced_data = all_balanced_data.set_index('Conf')\n",
    "#     all_balanced_data.loc[\"Z_1JTG_1136_M.pdb\",\"DDG_V\"]  = all_balanced_data[\"DDG_V\"].mean()\n",
    "    \n",
    "    all_unbalanced_data = dd.read_csv(\"../data/Clean_dataframe_unbalanced_all_data_ccharppi_4_march_2020_complete.csv\",dtype={'class_q': 'object'})\n",
    "    all_unbalanced_data = all_unbalanced_data.drop(\"class_q\",axis=1)\n",
    "    all_unbalanced_data = all_unbalanced_data.set_index('Conf')\n",
    "#     all_unbalanced_data.loc[\"Z_1JTG_1136_M.pdb\",\"DDG_V\"]  = all_balanced_data[\"DDG_V\"].mean()\n",
    "\n",
    "\n",
    "    Scorers_balanced_data = dd.read_csv(\"../data/Clean_dataframe_balanced_scorers_set_feb_12_2021.csv\")\n",
    "    Scorers_balanced_data = Scorers_balanced_data.set_index('Conf')\n",
    "    Scorers_balanced_data = Scorers_balanced_data.dropna()\n",
    "\n",
    "    Scorers_unbalanced_data = dd.read_csv(\"../data/Clean_dataframe_unbalanced_scorers_set_feb_12_2021.csv\")\n",
    "    Scorers_unbalanced_data = Scorers_unbalanced_data.set_index('Conf')\n",
    "    Scorers_unbalanced_data = Scorers_unbalanced_data.dropna()\n",
    "\n",
    "    X_train = all_balanced_data[~all_balanced_data[\"idx\"].isin(PDB_BM5) ]\n",
    "    y_train = all_balanced_data[~all_balanced_data[\"idx\"].isin(PDB_BM5) ][\"label_binary\"].astype('bool')\n",
    "\n",
    "            ## data set for less than 5 \n",
    "    X_val = all_balanced_data[all_balanced_data[\"idx\"].isin(PDB_BM5) ]\n",
    "    y_val = all_balanced_data[all_balanced_data[\"idx\"].isin(PDB_BM5) ][\"label_binary\"].astype('bool')\n",
    "    #         print (X_test.size,y_test.size)\n",
    "            ## data set for less than 5 \n",
    "    X_val_u = all_unbalanced_data[all_unbalanced_data[\"idx\"].isin(PDB_BM5) ]\n",
    "    y_val_u = all_unbalanced_data[all_unbalanced_data[\"idx\"].isin(PDB_BM5) ][\"label_binary\"].astype('bool')\n",
    "    \n",
    "    X_test = Scorers_balanced_data\n",
    "    y_test = Scorers_balanced_data[\"binary_label\"].astype('bool')\n",
    "    \n",
    "    X_test_u = Scorers_unbalanced_data\n",
    "    y_test_u = Scorers_unbalanced_data[\"binary_label\"].astype('bool')\n",
    "    \n",
    "    X_test_u = X_test_u.rename(columns={'NIS Polar' :'Nis_Polar',\n",
    "                                  'Nis Apolar':'Nis_Apolar',\n",
    "                                  'BSA Apolar':'BSA_Apolar',\n",
    "                                  'BSA Polar' :'BSA_Polar',\n",
    "                                'binary_label':'label_binary'\n",
    "                            })\n",
    "    X_test= X_test.rename(columns={'NIS Polar' :'Nis_Polar',\n",
    "                                  'Nis Apolar':'Nis_Apolar',\n",
    "                                  'BSA Apolar':'BSA_Apolar',\n",
    "                                  'BSA Polar' :'BSA_Polar',\n",
    "                                   'binary_label':'label_binary'\n",
    "                          })\n",
    "    \n",
    "#     for x in X_val_u.columns:\n",
    "#         if x not in X_test.columns:\n",
    "#             print (x)\n",
    "    return X_train, y_train , X_val, y_val, X_test, y_test ,X_val_u, y_val_u, X_test_u, y_test_u "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "designed-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_data_selected(X_train,X_test,X_test_unbalanced):\n",
    "#     scaler = MinMaxScaler()\n",
    "    scaler = StandardScaler()\n",
    "    selected_feat = ['AP_DFIRE2','AP_PISA','AP_T1','AP_T2','CP_MJ3h','SIPPER','ELE','VDW','PYDOCK_TOT','AP_dDFIRE']\n",
    "\n",
    "\n",
    "#     selected_feat = ['CONSRANK_val','AP_GOAP_DF','CP_TD','CP_D1','CP_HLPL',\n",
    "#                       'DDG_V','CP_MJ3h','PYDOCK_TOT','ELE','CP_SKOIP',\n",
    "#                       'SIPPER','AP_DFIRE2','AP_dDFIRE','AP_PISA','CP_RMFCA',\n",
    "# #                      'CP_TB','AP_DARS','CP_BT'\n",
    "#                      ]\n",
    "    \n",
    "#     selected_feat = ['CONSRANK_val','CP_HLPL','CP_MJ3h','DDG_V','CP_RMFCA','AP_GOAP_DF','CP_Qp','CP_TD','CP_SKOIP','CP_TB','CP_TSC','PYDOCK_TOT','SIPPER',\n",
    "# 'CP_BT','CP_MJ2h','AP_DFIRE2','CP_RMFCEN1','AP_DARS','AP_PISA','BSA_Apolar','CP_BFKV','AP_dDFIRE','CP_RMFCEN2','CP_ZS3DC_MIN',\n",
    "# 'AP_DDG_U','AP_DDG_W','cips_AlAr','CP_MJPL','CP_SKOb','CP_TEl','CP_TS','PROPNSTS','AP_MPS','CP_D1','FIREDOCK','AlAr','ArAr']\n",
    "\n",
    "    X_train = X_train[selected_feat]\n",
    "    X_test = X_test[selected_feat]\n",
    "    X_test_unbalanced= X_test_unbalanced[selected_feat]\n",
    "\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "    scaled_train = scaler.transform(X_train)\n",
    "    scaled_test = scaler.transform(X_test)\n",
    "    scaled_test_u = scaler.transform(X_test_unbalanced)\n",
    "    pickle.dump(scaler, open(\"ScalerBM4.pickle.dat\", \"wb\"))\n",
    "\n",
    "    return scaled_train,scaled_test,scaled_test_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seventh-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_data(X_train,X_test,X_test_unbalanced):\n",
    "#     scaler = MinMaxScaler()\n",
    "    features = ['idx','class_q','pdb1','chains_pdb1','pdb2','chains_pdb2',\n",
    "                'label_binary','DQ_val','binary_label','identification','labels']\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    for x in features :\n",
    "        if x in X_train.columns:\n",
    "            X_train= X_train.drop(x,axis=1)            \n",
    "    for x in features :\n",
    "        if x in X_test.columns: \n",
    "                X_test = X_test.drop(x,axis=1)\n",
    "            \n",
    "    for x in features :\n",
    "        if x in X_test_unbalanced.columns:\n",
    "            X_test_unbalanced= X_test_unbalanced.drop(x,axis=1)\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "    scaled_train = scaler.transform(X_train)\n",
    "    scaled_test = scaler.transform(X_test)\n",
    "    scaled_test_u = scaler.transform(X_test_unbalanced)\n",
    "    return scaled_train,scaled_test,scaled_test_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-interface",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fixed-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train , X_val, y_val, X_test, y_test ,X_val_u, y_val_u, X_test_u, y_test_u  = load_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personal-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"hidden_layer_sizes\": [\n",
    "\n",
    "        (24, ),\n",
    "        (12, 12),\n",
    "        (6, 6, 6, 6),\n",
    "        (4, 4, 4, 4, 4, 4),\n",
    "        (12, 6, 3, 3),\n",
    "    ],\n",
    "    \"activation\": [\"relu\", \"logistic\", \"tanh\"],\n",
    "    \"alpha\": np.logspace(-6, -3, num=1000),  # cnts\n",
    "    \"batch_size\": [16, 32, 64, 128, 256, 512],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continent-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conscious-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_w, X_test_w, X_test_u_w = scaling_data(X_train, X_test, X_test_u)\n",
    "# X_train_w, X_val_w, X_val_u_w = scaling_data(X_train, X_val, X_val_u)\n",
    "\n",
    "X_train_fs, X_test_fs, X_test_u_fs = scaling_data_selected(X_train, X_test, X_test_u)\n",
    "X_train_fs, X_val_fs, X_val_u_fs = scaling_data_selected(X_train, X_val, X_val_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "general-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 4 * len(X_train_fs)  # 20 passes through dataset for best model\n",
    "n_params = 8  # sample about 300 parameters\n",
    "\n",
    "# inputs to hyperband\n",
    "max_iter = n_params\n",
    "chunk_size = n_examples // n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-chamber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "absolute-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 10 entries, AP_DFIRE2 to AP_dDFIRE\n",
      "dtypes: float64(10)"
     ]
    }
   ],
   "source": [
    "X_train_fs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "engaging-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP_DFIRE2</th>\n",
       "      <th>AP_PISA</th>\n",
       "      <th>AP_T1</th>\n",
       "      <th>AP_T2</th>\n",
       "      <th>CP_MJ3h</th>\n",
       "      <th>SIPPER</th>\n",
       "      <th>ELE</th>\n",
       "      <th>VDW</th>\n",
       "      <th>PYDOCK_TOT</th>\n",
       "      <th>AP_dDFIRE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: describe-numeric, 131 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              AP_DFIRE2  AP_PISA    AP_T1    AP_T2  CP_MJ3h   SIPPER      ELE      VDW PYDOCK_TOT AP_dDFIRE\n",
       "npartitions=1                                                                                              \n",
       "                float64  float64  float64  float64  float64  float64  float64  float64    float64   float64\n",
       "                    ...      ...      ...      ...      ...      ...      ...      ...        ...       ...\n",
       "Dask Name: describe-numeric, 131 tasks"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "qualified-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = X_train_fs.to_dask_array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "provincial-blade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 4.46 MB </td> <td> 2.55 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (55748, 10) </td> <td> (31885, 10) </td></tr>\n",
       "    <tr><th> Count </th><td> 39 Tasks </td><td> 2 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"51\" x2=\"25\" y2=\"51\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 25.412617,0.000000 25.412617,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">55748</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<values, shape=(55748, 10), dtype=float64, chunksize=(31885, 10), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fs.compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "owned-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = X_train_fs.rechunk(chunks=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "altered-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sufficient-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_dask_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "monthly-nursery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 55.75 kB </td> <td> 31.89 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (55748,) </td> <td> (31885,) </td></tr>\n",
       "    <tr><th> Count </th><td> 37 Tasks </td><td> 2 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> bool </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"51\" y1=\"0\" x2=\"51\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,25.412617 0.000000,25.412617\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >55748</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<values, shape=(55748,), dtype=bool, chunksize=(31885,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "frequent-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.rechunk(chunks=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "careful-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-phase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "medium-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random search model\n",
    "rsnn = HyperbandSearchCV(estimator=estimator, parameters=params ,verbose=True,\n",
    "                         max_iter=max_iter,patience=True,\n",
    "                         random_state=32,aggressiveness=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "lovely-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsnn.metadata[\"partial_fit_calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "white-broadway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV, bracket=1] creating 4 models\n",
      "[CV, bracket=0] creating 2 models\n",
      "[CV, bracket=1] For training there are between 22299 and 22299 examples in each chunk\n",
      "[CV, bracket=0] For training there are between 22299 and 22299 examples in each chunk\n",
      "[CV, bracket=0] validation score of 0.7803 received after 1 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7711 received after 1 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7766 received after 2 partial_fit calls\n",
      "[CV, bracket=0] validation score of 0.7787 received after 3 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7804 received after 4 partial_fit calls\n",
      "[CV, bracket=0] validation score of 0.7757 received after 5 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7809 received after 6 partial_fit calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyperbandSearchCV(aggressiveness=4, estimator=MLPClassifier(), max_iter=8,\n",
       "                  parameters={'activation': ['relu', 'logistic', 'tanh'],\n",
       "                              'alpha': array([1.00000000e-06, 1.00693863e-06, 1.01392541e-06, 1.02096066e-06,\n",
       "       1.02804473e-06, 1.03517796e-06, 1.04236067e-06, 1.04959323e-06,\n",
       "       1.05687597e-06, 1.06420924e-06, 1.07159340e-06, 1.07902879e-06,\n",
       "       1.08651577e-06, 1.09405471e-06, 1...\n",
       "       9.01477631e-04, 9.07732653e-04, 9.14031075e-04, 9.20373200e-04,\n",
       "       9.26759330e-04, 9.33189772e-04, 9.39664831e-04, 9.46184819e-04,\n",
       "       9.52750047e-04, 9.59360829e-04, 9.66017480e-04, 9.72720319e-04,\n",
       "       9.79469667e-04, 9.86265846e-04, 9.93109181e-04, 1.00000000e-03]),\n",
       "                              'batch_size': [16, 32, 64, 128, 256, 512],\n",
       "                              'hidden_layer_sizes': [(24,), (12, 12),\n",
       "                                                     (6, 6, 6, 6),\n",
       "                                                     (4, 4, 4, 4, 4, 4),\n",
       "                                                     (12, 6, 3, 3)]},\n",
       "                  patience=True, random_state=32, verbose=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed = 101) \n",
    "\n",
    "rsnn.fit(X_train_fs,y_train,classes=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "digital-management",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (24,), 'batch_size': 32, 'alpha': 1.1805165285688055e-06, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print (rsnn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "filled-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = rsnn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "liberal-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= classifier.predict(X_val_u_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "discrete-proceeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.76      0.85    146541\n",
      "        True       0.16      0.59      0.25     11226\n",
      "\n",
      "    accuracy                           0.75    157767\n",
      "   macro avg       0.56      0.67      0.55    157767\n",
      "weighted avg       0.90      0.75      0.80    157767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report( y_true=y_val_u ,y_pred= y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dense-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= classifier.predict(X_test_u_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suitable-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.43      0.60     14283\n",
      "        True       0.19      0.97      0.31      1899\n",
      "\n",
      "    accuracy                           0.50     16182\n",
      "   macro avg       0.59      0.70      0.46     16182\n",
      "weighted avg       0.90      0.50      0.57     16182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report( y_true=y_test_u ,y_pred= y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-italy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "proprietary-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SGDClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-doubt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "latin-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SGD params \n",
    "params = { \n",
    "    \"l1_ratio\": uniform(0, 1), \n",
    "    \"alpha\": loguniform(1e-5, 1e-1), \n",
    "    \"penalty\": [\"l2\", \"l1\", \"elasticnet\"], \n",
    "    \"learning_rate\": [\"invscaling\", \"adaptive\",\"optimal\"], \n",
    "    \"power_t\": uniform(0, 1), \n",
    "    \"average\": [True, False], \n",
    "    \"loss\":[\"squared_loss\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"], \n",
    "    \"epsilon\": loguniform(1e-5, 1e-1), \n",
    "    \"eta0\":np.logspace(-6, -3, num=1000)\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "municipal-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsnn = HyperbandSearchCV(estimator=estimator, parameters=params ,verbose=True,\n",
    "                         max_iter=max_iter,patience=True,\n",
    "                         random_state=32,aggressiveness=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "progressive-belarus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsnn.metadata[\"partial_fit_calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aerial-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV, bracket=1] creating 4 models\n",
      "[CV, bracket=0] creating 2 models\n",
      "[CV, bracket=1] For training there are between 22299 and 22299 examples in each chunk\n",
      "[CV, bracket=0] For training there are between 22299 and 22299 examples in each chunk\n",
      "[CV, bracket=0] validation score of 0.7703 received after 1 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7608 received after 1 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7735 received after 2 partial_fit calls\n",
      "[CV, bracket=0] validation score of 0.7779 received after 3 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7749 received after 4 partial_fit calls\n",
      "[CV, bracket=0] validation score of 0.7800 received after 5 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.7755 received after 6 partial_fit calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HyperbandSearchCV(aggressiveness=4, estimator=SGDClassifier(), max_iter=8,\n",
       "                  parameters={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x15670c790>,\n",
       "                              'average': [True, False],\n",
       "                              'epsilon': <scipy.stats._distn_infrastructure.rv_frozen object at 0x15670ce80>,\n",
       "                              'eta0': array([1.00000000e-06, 1.00693863e-06, 1.01392541e-06, 1.02096066e-06,\n",
       "       1.02804473e-06, 1.0351...\n",
       "                              'l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object at 0x15670c520>,\n",
       "                              'learning_rate': ['invscaling', 'adaptive',\n",
       "                                                'optimal'],\n",
       "                              'loss': ['squared_loss', 'huber',\n",
       "                                       'epsilon_insensitive',\n",
       "                                       'squared_epsilon_insensitive'],\n",
       "                              'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                              'power_t': <scipy.stats._distn_infrastructure.rv_frozen object at 0x15670cd90>},\n",
       "                  patience=True, random_state=32, verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed = 101) \n",
    "\n",
    "rsnn.fit(X_train_fs,y_train,classes=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "anonymous-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.027261959556018345, 'average': False, 'epsilon': 0.0004832278256276128, 'eta0': 0.0007531420165974368, 'l1_ratio': 0.9556565489917677, 'learning_rate': 'invscaling', 'loss': 'squared_epsilon_insensitive', 'penalty': 'elasticnet', 'power_t': 0.35360111371492264}\n"
     ]
    }
   ],
   "source": [
    "print ( rsnn.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "transparent-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = rsnn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "green-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= classifier.predict(X_val_u_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "radio-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.75      0.84    146541\n",
      "        True       0.16      0.61      0.25     11226\n",
      "\n",
      "    accuracy                           0.74    157767\n",
      "   macro avg       0.56      0.68      0.55    157767\n",
      "weighted avg       0.90      0.74      0.80    157767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report( y_true=y_val_u ,y_pred= y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "rolled-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= classifier.predict(X_test_u_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "promising-acceptance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.40      0.57     14283\n",
      "        True       0.18      0.98      0.30      1899\n",
      "\n",
      "    accuracy                           0.47     16182\n",
      "   macro avg       0.59      0.69      0.44     16182\n",
      "weighted avg       0.90      0.47      0.54     16182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report( y_true=y_test_u ,y_pred= y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-accordance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "quantitative-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-tumor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "egyptian-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = { \n",
    "# \"learning_rate\" :[0.0001, 0.001, 0.01, 0.1], \n",
    "#  \"n_estimators\":np.linspace(start = 100, stop = 1000, num = 5),\n",
    "# #  \"max_depth\":np.linspace(1, 11, num = 10),\n",
    "# #  \"min_child_weight\": np.linspace(1, 11, num = 10),\n",
    "# #  \"gamma\":[0,2,4,6,8],\n",
    "# #  \"subsample\":np.linspace(0,1,num=10),\n",
    "# #  \"colsample_bytree\":np.linspace(0,1,num=10),\n",
    "#  \"objective\": ['binary:logistic','binary:logitraw','binary:hinge']\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "directed-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_encoded_y = LabelEncoder().fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "automatic-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsnn.metadata[\"partial_fit_calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "facial-birmingham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='approx', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed = 101) \n",
    "xgb.fit(X_train_fs,y_train)\n",
    "# rsnn.fit(X_train_fs,y_train,classes=[True,False])\n",
    "# random_S.fit(X_train_fs.compute(),y_train.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "satisfied-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= xgb.predict(X_test_u_fs.to_dask_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "administrative-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.56      0.71     14283\n",
      "        True       0.21      0.89      0.34      1899\n",
      "\n",
      "    accuracy                           0.60     16182\n",
      "   macro avg       0.59      0.72      0.52     16182\n",
      "weighted avg       0.88      0.60      0.67     16182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report( y_true=y_test_u ,y_pred= y_pred.compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "phantom-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= xgb.predict(X_val_u_fs.to_dask_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "supreme-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.79      0.86    146541\n",
      "        True       0.17      0.59      0.27     11226\n",
      "\n",
      "    accuracy                           0.77    157767\n",
      "   macro avg       0.57      0.69      0.57    157767\n",
      "weighted avg       0.91      0.77      0.82    157767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report( y_true=y_val_u ,y_pred= y_pred.compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "impressed-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "nuclear-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(seed = 101) \n",
    "\n",
    "# # rsnn = HyperbandSearchCV(estimator=xgb, parameters=params ,verbose=True,\n",
    "# #                          max_iter=max_iter,patience=True,\n",
    "# #                          random_state=32,aggressiveness=4)\n",
    "# # kfold = KFold(n_splits=10, shuffle=True, random_state=101)\n",
    "\n",
    "# random_S = RandomizedSearchCV(estimator = xgb,\n",
    "#                               param_distributions = params,\n",
    "#                               scoring=\"neg_log_loss\",\n",
    "# #                               cv = kfold,\n",
    "#                               random_state=101, \n",
    "#                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "centered-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(label_encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "portuguese-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_S.fit(X_train_fs,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "naughty-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( random_S.best_estimator_ ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "retained-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.56      0.71     14283\n",
      "        True       0.21      0.89      0.34      1899\n",
      "\n",
      "    accuracy                           0.60     16182\n",
      "   macro avg       0.59      0.72      0.52     16182\n",
      "weighted avg       0.88      0.60      0.67     16182\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.63      0.76     14283\n",
      "        True       0.23      0.82      0.35      1899\n",
      "\n",
      "    accuracy                           0.65     16182\n",
      "   macro avg       0.59      0.72      0.56     16182\n",
      "weighted avg       0.88      0.65      0.71     16182\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.57      0.71     14283\n",
      "        True       0.19      0.78      0.31      1899\n",
      "\n",
      "    accuracy                           0.59     16182\n",
      "   macro avg       0.57      0.67      0.51     16182\n",
      "weighted avg       0.86      0.59      0.66     16182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed = 101) \n",
    "# xgb.fit(X_train_fs,y_train)\n",
    "# rsnn.fit(X_train_fs,y_train,classes=[True,False])\n",
    "# random_S.fit(X_train_fs,y_train)\n",
    "for x in  ['binary:logistic','binary:logitraw','binary:hinge']:\n",
    "    xgb = XGBClassifier(objective=x)\n",
    "    xgb.fit(X_train_fs,y_train)\n",
    "    y_pred= xgb.predict(X_test_u_fs.to_dask_array())\n",
    "    print (classification_report( y_true=y_test_u ,y_pred= y_pred.compute()))\n",
    "    print ()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "upper-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.63      0.76     14283\n",
      "        True       0.23      0.82      0.35      1899\n",
      "\n",
      "    accuracy                           0.65     16182\n",
      "   macro avg       0.59      0.72      0.56     16182\n",
      "weighted avg       0.88      0.65      0.71     16182\n",
      "\n",
      "\n",
      "325.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.63      0.76     14283\n",
      "        True       0.23      0.85      0.36      1899\n",
      "\n",
      "    accuracy                           0.65     16182\n",
      "   macro avg       0.60      0.74      0.56     16182\n",
      "weighted avg       0.88      0.65      0.71     16182\n",
      "\n",
      "\n",
      "550.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.62      0.76     14283\n",
      "        True       0.23      0.86      0.36      1899\n",
      "\n",
      "    accuracy                           0.65     16182\n",
      "   macro avg       0.60      0.74      0.56     16182\n",
      "weighted avg       0.88      0.65      0.71     16182\n",
      "\n",
      "\n",
      "775.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.62      0.75     14283\n",
      "        True       0.23      0.85      0.36      1899\n",
      "\n",
      "    accuracy                           0.64     16182\n",
      "   macro avg       0.60      0.74      0.56     16182\n",
      "weighted avg       0.88      0.64      0.71     16182\n",
      "\n",
      "\n",
      "1000.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.61      0.75     14283\n",
      "        True       0.23      0.86      0.36      1899\n",
      "\n",
      "    accuracy                           0.64     16182\n",
      "   macro avg       0.60      0.74      0.56     16182\n",
      "weighted avg       0.88      0.64      0.71     16182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed = 101) \n",
    "# xgb.fit(X_train_fs,y_train)\n",
    "# rsnn.fit(X_train_fs,y_train,classes=[True,False])\n",
    "# random_S.fit(X_train_fs,y_train)\n",
    "for x in np.linspace(start = 100, stop = 1000, num = 5) :\n",
    "    print(x)\n",
    "    xgb = XGBClassifier(objective='binary:logitraw', n_estimators= int(x) )\n",
    "    \n",
    "    xgb.fit(X_train_fs,y_train)\n",
    "    y_pred= xgb.predict(X_test_u_fs.to_dask_array())\n",
    "    print (classification_report( y_true=y_test_u ,y_pred= y_pred.compute()))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "wicked-consent",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barradd/anaconda2/envs/dask-examples/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      1.00      0.94     14283\n",
      "        True       0.00      0.00      0.00      1899\n",
      "\n",
      "    accuracy                           0.88     16182\n",
      "   macro avg       0.44      0.50      0.47     16182\n",
      "weighted avg       0.78      0.88      0.83     16182\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barradd/anaconda2/envs/dask-examples/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      1.00      0.94     14283\n",
      "        True       0.00      0.00      0.00      1899\n",
      "\n",
      "    accuracy                           0.88     16182\n",
      "   macro avg       0.44      0.50      0.47     16182\n",
      "weighted avg       0.78      0.88      0.83     16182\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.54      0.69     14283\n",
      "        True       0.21      0.92      0.34      1899\n",
      "\n",
      "    accuracy                           0.58     16182\n",
      "   macro avg       0.59      0.73      0.52     16182\n",
      "weighted avg       0.89      0.58      0.65     16182\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.63      0.76     14283\n",
      "        True       0.23      0.82      0.35      1899\n",
      "\n",
      "    accuracy                           0.65     16182\n",
      "   macro avg       0.59      0.72      0.56     16182\n",
      "weighted avg       0.88      0.65      0.71     16182\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed = 101) \n",
    "# xgb.fit(X_train_fs,y_train)\n",
    "# rsnn.fit(X_train_fs,y_train,classes=[True,False])\n",
    "# random_S.fit(X_train_fs,y_train)\n",
    "learning_rate = [0.0003, 0.003, 0.03, 0.3]\n",
    "for x in  learning_rate:\n",
    "    xgb = XGBClassifier(objective='binary:logitraw',learning_rate=x)\n",
    "    xgb.fit(X_train_fs,y_train)\n",
    "    y_pred= xgb.predict(X_test_u_fs.to_dask_array())\n",
    "    print (classification_report( y_true=y_test_u ,y_pred= y_pred.compute()))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "protecting-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(objective='binary:logitraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "headed-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:logitraw', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='approx', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train_fs,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "hungry-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.85      0.90    146541\n",
      "        True       0.20      0.47      0.28     11226\n",
      "\n",
      "    accuracy                           0.83    157767\n",
      "   macro avg       0.58      0.66      0.59    157767\n",
      "weighted avg       0.90      0.83      0.86    157767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= xgb.predict(X_val_u_fs.to_dask_array())\n",
    "cr = classification_report( y_true=y_val_u ,y_pred= y_pred.compute())\n",
    "print (cr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "accredited-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.63      0.76     14283\n",
      "        True       0.23      0.82      0.35      1899\n",
      "\n",
      "    accuracy                           0.65     16182\n",
      "   macro avg       0.59      0.72      0.56     16182\n",
      "weighted avg       0.88      0.65      0.71     16182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= xgb.predict(X_test_u_fs.to_dask_array())\n",
    "cr = classification_report( y_true=y_test_u ,y_pred= y_pred.compute())\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-element",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "younger-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb, open(\"XgbClassBM4.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.predict_proba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
